{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Model Monitoring, Drift Detection, and Retraining Strategy\n",
    "\n",
    "Welcome to the final lab! We've built a pipeline, trained a model, and deployed it as an API. But the work isn't done. Models in production can become stale as the world changes. In this lab, we'll learn how to monitor our model for **drift** and outline a strategy for automated retraining to keep our model fresh and accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "- Understand the concepts of Data Drift and Concept Drift.\n",
    "- Use the **Evidently AI** library to generate a drift report.\n",
    "- Compare a reference dataset (training data) with a current dataset (production data).\n",
    "- Interpret the drift report to identify changes in your data.\n",
    "- Formulate a strategy for an automated retraining pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup: Installing Dependencies\n",
    "\n",
    "Our key tool for this lab is `evidently`, an open-source library for evaluating, testing, and monitoring ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install evidently pandas scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Key Concepts: Model Drift\n",
    "\n",
    "Model drift (or model decay) is the degradation of a model's predictive power due to changes in the environment. There are two main types:\n",
    "\n",
    "**Data Drift:** The statistical properties of the input features change. For example, the average `Balance` of new customers might increase, or the `Age` distribution might shift. The model is now seeing data it wasn't trained on, which can lead to inaccurate predictions.\n",
    "\n",
    "**Concept Drift:** The relationship between the features and the target variable changes. For example, a new banking regulation might change what factors cause a customer to churn. The patterns the model learned are no longer valid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Simulating Production Data\n",
    "\n",
    "To detect drift, we need to compare the data our model was trained on (**reference** data) with the data it's seeing now in production (**current** data). Since we don't have a live application, we'll simulate this by taking our original dataset and modifying it to create a 'current' dataset with intentional drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the original processed data as our 'reference' dataset\n",
    "reference_df = pd.read_parquet('../../data/churn_processed.parquet')\n",
    "\n",
    "# Create a 'current' dataset by sampling and modifying the reference data\n",
    "current_df = reference_df.sample(n=5, random_state=42).copy()\n",
    "\n",
    "# Introduce some data drift\n",
    "print(\"Original 'current' data:\\n\", current_df[['Age', 'Balance', 'IsActiveMember']])\n",
    "current_df['Age'] = current_df['Age'] + 10  # All customers are now older\n",
    "current_df['Balance'] = current_df['Balance'] * 1.5 # Balances have increased\n",
    "current_df['IsActiveMember'] = 0 # All of these customers became inactive\n",
    "print(\"\\nModified 'current' data with drift:\\n\", current_df[['Age', 'Balance', 'IsActiveMember']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generating a Drift Report with Evidently AI\n",
    "\n",
    "Now, let's use Evidently to compare our `reference_df` and `current_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "\n",
    "# Create a report and add the DataDriftPreset\n",
    "data_drift_report = Report(metrics=[\n",
    "    DataDriftPreset(),\n",
    "])\n",
    "\n",
    "# Run the report\n",
    "data_drift_report.run(reference_data=reference_df, current_data=current_df)\n",
    "\n",
    "# Display the report directly in the notebook\n",
    "data_drift_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Interpreting the Report\n",
    "\n",
    "The interactive report above gives you a complete picture of the data drift.\n",
    "\n",
    "- **Data Drift Detected:** At the top, Evidently gives a clear verdict on whether significant drift has occurred.\n",
    "- **Feature-level Drift:** You can see a breakdown of each feature. For features where drift is detected (like `Age`, `Balance`, and `IsActiveMember` in our simulation), you can see how their statistical distributions have changed between the reference and current datasets.\n",
    "- **P-value:** The p-value for each feature's drift test is shown. A low p-value (typically < 0.05) indicates significant drift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Strategy for Automated Retraining\n",
    "\n",
    "Generating a report is great, but in a real MLOps system, we want to act on it. This is where we close the loop by setting up an automated retraining pipeline.\n",
    "\n",
    "Here's how all the pieces of our tutorial would fit together in a production system:\n",
    "\n",
    "1. **Scheduled Monitoring:** A scheduled job (e.g., a daily cron job or a Prefect flow) runs the drift detection analysis using Evidently. It compares the latest production data with the original training data.\n",
    "\n",
    "2. **Drift Threshold:** The job checks the output of the Evidently report (which can be exported as a JSON object). If the number of drifted features or the overall drift score exceeds a predefined threshold, it decides that retraining is necessary.\n",
    "\n",
    "3. **Trigger Retraining:** If the threshold is breached, the monitoring service makes an API call to trigger a new pipeline run. This could be a webhook to a CI/CD system or, in our case, a call to trigger our **Prefect `etl_flow` from Lab 1**.\n",
    "\n",
    "4. **Automated ETL and AutoML:** The Prefect flow from Lab 1 runs, processing the new raw data. The output of this flow then becomes the input for our **AutoML process from Lab 2**. A new, better model is trained on the fresh data and registered in the MLflow Registry.\n",
    "\n",
    "5. **Automated Deployment (Optional):** A CI/CD pipeline could then automatically deploy the new model version, for example, by updating the stage of the new model to \"Production\", so our FastAPI app from Lab 3 picks it up.\n",
    "\n",
    "This creates a closed-loop system that automatically detects when a model is going stale and retrains and redeploys a new version, ensuring the business is always using the most accurate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Tutorial Conclusion\n",
    "\n",
    "**Congratulations!** You have completed the entire MLOps tutorial.\n",
    "\n",
    "You have gone through the full, end-to-end lifecycle of a machine learning system, mirroring the practices of top AI teams:\n",
    "\n",
    "- **Lab 1:** You built a scalable ETL pipeline with **Prefect** and **Dask**.\n",
    "- **Lab 2:** You ran an AutoML workflow with **PyCaret** and tracked it with **MLflow**.\n",
    "- **Lab 3:** You deployed the model as a resilient **FastAPI** microservice.\n",
    "- **Lab 4:** You learned how to monitor for drift with **Evidently AI** and designed an automated retraining strategy.\n",
    "\n",
    "You now have a production-ready MLOps stack running locally and a solid, practical understanding of how to build and maintain real-world machine learning systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
