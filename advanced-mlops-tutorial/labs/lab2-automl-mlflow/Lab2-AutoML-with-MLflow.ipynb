{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: AutoML with PyCaret and MLflow\n",
    "\n",
    "Welcome to Lab 2! Now that we have a clean, processed dataset from our ETL pipeline, it's time to train a machine learning model. Instead of manually trying out different models, we'll use an AutoML (Automated Machine Learning) tool, **PyCaret**, to automatically find the best model for our problem. We'll also use **MLflow** to track every experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "- Understand the benefits of AutoML.\n",
    "- Use PyCaret to set up an ML experiment and compare multiple models with a single command.\n",
    "- Leverage PyCaret's seamless integration with MLflow to automatically log experiments.\n",
    "- Identify the best model from the experiments and register it in the MLflow Model Registry for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup: Installing Dependencies\n",
    "\n",
    "PyCaret has a rich set of features, and installing it with `[full]` ensures all optional dependencies are included. We also need `mlflow` for tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pycaret[full] mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading the Processed Data\n",
    "\n",
    "Let's start by loading the processed data we created in Lab 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PROCESSED_DATA_PATH = '../../data/churn_processed.parquet'\n",
    "df = pd.read_parquet(PROCESSED_DATA_PATH)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Understanding AutoML and PyCaret\n",
    "\n",
    "**AutoML** automates the tasks of model selection, hyperparameter tuning, and feature engineering. It helps data scientists to quickly build high-performing models without extensive manual effort.\n",
    "\n",
    "**PyCaret** is a low-code AutoML library in Python that makes this process incredibly simple. It acts as a wrapper around many ML libraries (like scikit-learn, XGBoost, LightGBM) and provides a consistent and easy-to-use API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Setting up the PyCaret Experiment\n",
    "\n",
    "The first step is to initialize the experiment using the `setup()` function. This function handles all the data preprocessing steps (like one-hot encoding, scaling, etc.). We will also tell PyCaret to automatically log everything to MLflow by setting `log_experiment=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "import mlflow\n",
    "\n",
    "# Set the MLflow tracking URI. PyCaret will use this.\n",
    "# This assumes you run this notebook from its directory.\n",
    "mlflow.set_tracking_uri('../../mlruns')\n",
    "\n",
    "# Initialize the PyCaret environment\n",
    "exp = setup(\n",
    "    data=df,\n",
    "    target='Exited',  # Our target variable\n",
    "    session_id=123,  # for reproducibility\n",
    "    log_experiment=True, # Enable MLflow logging\n",
    "    experiment_name='churn_prediction_automl', # Name of the MLflow experiment\n",
    "    ignore_features=['CustomerID'] # Ignore irrelevant features\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training and Comparing All Models\n",
    "\n",
    "This is where the magic happens! With a single line of code, PyCaret will train and evaluate over a dozen different classification models using cross-validation and display the results in a sortable grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Analyzing Results in the MLflow UI\n",
    "\n",
    "Because we set `log_experiment=True`, PyCaret has logged every single model it trained as a separate run in MLflow. Let's explore this.\n",
    "\n",
    "1. **Open a new terminal or command prompt.**\n",
    "2. **Navigate to the root directory of this project** (`advanced-mlops-tutorial`).\n",
    "3. **Run the command:** `mlflow ui`\n",
    "4. **Open your browser** and go to `http://localhost:5000`.\n",
    "\n",
    "In the MLflow UI, you will find the `churn_prediction_automl` experiment. Click on it to see all the runs. You can sort them by metrics like 'Accuracy' or 'AUC' and click on any run to see the parameters, metrics, and artifacts (like confusion matrix, feature importance) that PyCaret automatically logged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Registering the Best Model in MLflow\n",
    "\n",
    "The final step is to take our best performing model and register it in the **MLflow Model Registry**. The registry is a centralized place to manage the lifecycle of your models (e.g., moving them from Staging to Production).\n",
    "\n",
    "We will first finalize the model (retrain it on the full dataset) and then find its corresponding run in MLflow to register it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize the model (retrains on the full dataset)\n",
    "final_model = finalize_model(best_model)\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the model\n",
    "model_name = \"churn-classifier\"\n",
    "model_uri = f\"runs:/{get_config('mlflow_run_id')}/model\"\n",
    "\n",
    "registered_model = mlflow.register_model(\n",
    "    model_uri=model_uri,\n",
    "    name=model_name\n",
    ")\n",
    "\n",
    "print(f\"Model '{model_name}' registered with version {registered_model.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if you go back to the MLflow UI and click on the **Models** tab, you will see your newly registered `churn-classifier` model. This is the model we will serve in the next lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Conclusion\n",
    "\n",
    "In this lab, you saw the power of AutoML with PyCaret. You were able to train, evaluate, and select the best model from a wide variety of candidates with just a few lines of code. You also saw how MLflow can be seamlessly integrated to keep track of all your experiments.\n",
    "\n",
    "In Lab 3, we will take the model we just registered and deploy it as a production-ready API using FastAPI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
